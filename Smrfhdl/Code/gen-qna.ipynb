{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10181116,"sourceType":"datasetVersion","datasetId":6289072},{"sourceId":10182115,"sourceType":"datasetVersion","datasetId":6289829},{"sourceId":10182883,"sourceType":"datasetVersion","datasetId":6290412}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install groq","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T13:37:33.840666Z","iopub.execute_input":"2024-12-12T13:37:33.840988Z","iopub.status.idle":"2024-12-12T13:37:43.716995Z","shell.execute_reply.started":"2024-12-12T13:37:33.840958Z","shell.execute_reply":"2024-12-12T13:37:43.715944Z"}},"outputs":[{"name":"stdout","text":"Collecting groq\n  Downloading groq-0.13.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from groq) (4.4.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from groq) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from groq) (0.27.0)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from groq) (2.10.1)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from groq) (1.3.1)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from groq) (4.12.2)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq) (3.7)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq) (1.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (2024.6.2)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (2.27.1)\nDownloading groq-0.13.0-py3-none-any.whl (108 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.8/108.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: groq\nSuccessfully installed groq-0.13.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport random\nfrom groq import Groq\n# import streamlit as st\nimport re\nimport time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:06:42.045387Z","iopub.execute_input":"2024-12-12T14:06:42.046284Z","iopub.status.idle":"2024-12-12T14:06:42.050233Z","shell.execute_reply.started":"2024-12-12T14:06:42.046248Z","shell.execute_reply":"2024-12-12T14:06:42.049382Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"class VietnameseDishChatbot:\n    def __init__(self, file_path):\n        self.df = pd.read_csv(file_path)\n        self.client = Groq(api_key='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')\n        self.system_prompts = {\n            'Dish': [\n                \"Create unique questions about the name and origin of the dish\",\n                \"Generate interesting questions related to the name and meaning of the dish\"\n            ],\n            'Description': [\n                \"Create in-depth questions exploring the characteristics and culture of the dish\",\n                \"Generate questions that highlight interesting details in the description\"\n            ],\n            'Recipe': [\n                \"Create specialized questions about cooking techniques\",\n                \"Generate questions related to ingredients and preparation methods\"\n            ],\n            'Similar_Dishes': [\n                \"Create comparison questions to distinguish similar dishes\",\n                \"Generate questions exploring the relationships between dishes\"\n            ],\n            'Famous_Restaurants': [\n                \"Create questions about famous culinary locations\",\n                \"Generate questions exploring local culinary culture\"\n            ]\n        }\n\n    def generate_qa_with_retry(self, dish, attribute, max_retries=3):\n        \"\"\"Generate Q&A with retry mechanism\"\"\"\n        for attempt in range(max_retries):\n            try:\n                system_prompt = random.choice(self.system_prompts[attribute])\n                \n                response = self.client.chat.completions.create(\n                    messages=[\n                        {\n                            \"role\": \"system\", \n                            \"content\": f\"{system_prompt}. You are a Vietnamese culinary expert.\"\n                        },\n                        {\n                            \"role\": \"user\", \n                            \"content\": f\"\"\"Information about {dish}: \n                            {attribute}: {self.df.loc[self.df['Dish'] == dish, attribute].values[0]}\n                            \n                            Create an original question and an in-depth answer.\"\"\"\n                        }\n                    ],\n                    model=\"mixtral-8x7b-32768\",\n                    max_tokens=8192\n                )\n\n                full_response = response.choices[0].message.content\n                \n                # Find question and answer\n                qa_match = re.findall(r'Question:\\s*(.+)\\n*Answer:\\s*(.+)', full_response, re.DOTALL)\n                \n                if qa_match:\n                    question, answer = qa_match[0]\n                    return {\n                        'Dish': dish,\n                        'Attribute': attribute,\n                        'Question': question.strip(),\n                        'Answer': answer.strip()\n                    }\n                \n                # If no match, try alternative approach\n                return {\n                    'Dish': dish,\n                    'Attribute': attribute,\n                    'Question': f\"Details about {attribute} of {dish}?\",\n                    'Answer': full_response.strip()\n                }\n            \n            except Exception as e:\n                print(f\"Error on attempt {attempt + 1} for {dish} - {attribute}: {e}\")\n                time.sleep(2)  # Wait between attempts\n        \n        # Return default value if out of retries\n        return {\n            'Dish': dish,\n            'Attribute': attribute,\n            'Question': f\"Information about {attribute} of {dish}\",\n            'Answer': \"Unable to generate question and answer.\"\n        }\n\n    def generate_comprehensive_qa_dataset(self, batch_size=5):  # Added default value here\n        \"\"\"Generate Q&A by batch to optimize time\"\"\"\n        all_qa_pairs = []\n        attributes = ['Dish', 'Description', 'Recipe', 'Similar_Dishes', 'Famous_Restaurants']\n        \n        # Split into batches for processing\n        for i in range(0, len(self.df), batch_size):\n            batch_dishes = self.df['Dish'][i:i+batch_size]\n            \n            batch_qa_pairs = []\n            for dish in batch_dishes:\n                dish_qa_pairs = []\n                for attribute in attributes:\n                    # Generate 5 Q&A for each attribute\n                    for _ in range(5):\n                        qa_pair = self.generate_qa_with_retry(dish, attribute)\n                        dish_qa_pairs.append(qa_pair)\n                \n                batch_qa_pairs.extend(dish_qa_pairs)\n                \n                # Print progress\n                print(f\"Processed {dish}\")\n                \n                # Short wait between calls\n                time.sleep(1)\n            \n            all_qa_pairs.extend(batch_qa_pairs)\n            \n            # Save each batch in case of error\n            batch_df = pd.DataFrame(all_qa_pairs)\n            batch_df.to_csv(f'vietnamese_dishes_qa_batch_{i//batch_size + 1}.csv', \n                             index=False, encoding='utf-8-sig')\n        \n        return pd.DataFrame(all_qa_pairs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T16:39:29.123473Z","iopub.execute_input":"2024-12-12T16:39:29.123802Z","iopub.status.idle":"2024-12-12T16:39:29.135460Z","shell.execute_reply.started":"2024-12-12T16:39:29.123774Z","shell.execute_reply":"2024-12-12T16:39:29.134571Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"class VietnameseDishChatbotPart3:\n    def __init__(self, file_path):\n        self.df = pd.read_csv(file_path)\n        self.client = Groq(api_key='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')\n        self.system_prompts = {\n            'Dish': [\n                \"Create unique questions about the name and origin of the dish\",\n                \"Generate interesting questions related to the name and meaning of the dish\"\n            ],\n            'Description': [\n                \"Create in-depth questions exploring the characteristics and culture of the dish\",\n                \"Generate questions that highlight interesting details in the description\"\n            ],\n            'Recipe': [\n                \"Create specialized questions about cooking techniques\",\n                \"Generate questions related to ingredients and preparation methods\"\n            ],\n            'Similar_Dishes': [\n                \"Create comparison questions to distinguish similar dishes\",\n                \"Generate questions exploring the relationships between dishes\"\n            ],\n            'Famous_Restaurants': [\n                \"Create questions about famous culinary locations\",\n                \"Generate questions exploring local culinary culture\"\n            ]\n        }\n\n    def generate_qa_with_retry(self, dish, attribute, max_retries=3):\n        \"\"\"Generate Q&A with retry mechanism\"\"\"\n        for attempt in range(max_retries):\n            try:\n                system_prompt = random.choice(self.system_prompts[attribute])\n                \n                response = self.client.chat.completions.create(\n                    messages=[\n                        {\n                            \"role\": \"system\", \n                            \"content\": f\"{system_prompt}. You are a Vietnamese culinary expert.\"\n                        },\n                        {\n                            \"role\": \"user\", \n                            \"content\": f\"\"\"Information about {dish}: \n                            {attribute}: {self.df.loc[self.df['Dish'] == dish, attribute].values[0]}\n                            \n                            Create an original question and an in-depth answer.\"\"\"\n                        }\n                    ],\n                    model=\"mixtral-8x7b-32768\",\n                    max_tokens=8192\n                )\n\n                full_response = response.choices[0].message.content\n                \n                # Find question and answer\n                qa_match = re.findall(r'Question:\\s*(.+)\\n*Answer:\\s*(.+)', full_response, re.DOTALL)\n                \n                if qa_match:\n                    question, answer = qa_match[0]\n                    return {\n                        'Dish': dish,\n                        'Attribute': attribute,\n                        'Question': question.strip(),\n                        'Answer': answer.strip()\n                    }\n                \n                # If no match, try alternative approach\n                return {\n                    'Dish': dish,\n                    'Attribute': attribute,\n                    'Question': f\"Details about {attribute} of {dish}?\",\n                    'Answer': full_response.strip()\n                }\n            \n            except Exception as e:\n                print(f\"Error on attempt {attempt + 1} for {dish} - {attribute}: {e}\")\n                time.sleep(2)  # Wait between attempts\n        \n        # Return default value if out of retries\n        return {\n            'Dish': dish,\n            'Attribute': attribute,\n            'Question': f\"Information about {attribute} of {dish}\",\n            'Answer': \"Unable to generate question and answer.\"\n        }\n\n    def generate_comprehensive_qa_dataset(self, batch_size=5):  # Added default value here\n        \"\"\"Generate Q&A by batch to optimize time\"\"\"\n        all_qa_pairs = []\n        attributes = ['Dish', 'Description', 'Recipe', 'Similar_Dishes', 'Famous_Restaurants']\n        \n        # Split into batches for processing\n        for i in range(0, len(self.df), batch_size):\n            batch_dishes = self.df['Dish'][i:i+batch_size]\n            \n            batch_qa_pairs = []\n            for dish in batch_dishes:\n                dish_qa_pairs = []\n                for attribute in attributes:\n                    # Generate 5 Q&A for each attribute\n                    for _ in range(5):\n                        qa_pair = self.generate_qa_with_retry(dish, attribute)\n                        dish_qa_pairs.append(qa_pair)\n                \n                batch_qa_pairs.extend(dish_qa_pairs)\n                \n                # Print progress\n                print(f\"Processed {dish}\")\n                \n                # Short wait between calls\n                time.sleep(1)\n            \n            all_qa_pairs.extend(batch_qa_pairs)\n            \n            # Save each batch in case of error\n            batch_df = pd.DataFrame(all_qa_pairs)\n            batch_df.to_csv(f'vietnamese_dishes_qa_part3_batch_{i//batch_size + 1}.csv', \n                             index=False, encoding='utf-8-sig')\n        \n        return pd.DataFrame(all_qa_pairs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T16:48:28.341950Z","iopub.execute_input":"2024-12-12T16:48:28.342295Z","iopub.status.idle":"2024-12-12T16:48:28.354126Z","shell.execute_reply.started":"2024-12-12T16:48:28.342263Z","shell.execute_reply":"2024-12-12T16:48:28.353242Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"chatbot = VietnameseDishChatbotPart3('/kaggle/input/dataset3/dishes_from_hutieu.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T16:48:28.384939Z","iopub.execute_input":"2024-12-12T16:48:28.385161Z","iopub.status.idle":"2024-12-12T16:48:28.400179Z","shell.execute_reply.started":"2024-12-12T16:48:28.385136Z","shell.execute_reply":"2024-12-12T16:48:28.399650Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"qa_dataset = chatbot.generate_comprehensive_qa_dataset()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T16:48:33.134935Z","iopub.execute_input":"2024-12-12T16:48:33.135712Z","iopub.status.idle":"2024-12-12T17:15:50.022430Z","shell.execute_reply.started":"2024-12-12T16:48:33.135676Z","shell.execute_reply":"2024-12-12T17:15:50.021729Z"}},"outputs":[{"name":"stdout","text":"Processed Hủ tiếu\nProcessed Bánh cu đơ\nProcessed Nem nướng\nProcessed Bánh mì cay\nProcessed Cơm cháy\nProcessed Bò bía\nProcessed Bánh đậu xanh\nProcessed Bánh đa cua\nProcessed Bún cá\n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"qa_dataset.to_csv('comprehensive_vietnamese_dishes_qa.csv', index=False, encoding='utf-8-sig')","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(qa_dataset.sample(10))","metadata":{},"outputs":[],"execution_count":null}]}